import streamlit as st
import numpy as np
import pandas as pd
from modules.theme_toggle import initialize_theme, apply_styles
import plotly.graph_objs as go
from sklearn.linear_model import LinearRegression
from numpy.polynomial.polynomial import Polynomial
import pandasql as ps
import plotly.express as px
import plotly.graph_objects as go

# Inicializar el estado del tema
initialize_theme()

# Configuraci√≥n de la p√°gina
st.set_page_config(page_title="DS - WOMPI", page_icon=":bar_chart:", layout="wide")

# Aplicar los estilos seg√∫n el modo seleccionado
apply_styles()
st.markdown(
            """
            <style>
            .respuesta-box {
                background-color: #e6f4e6;
                border: 2px solid #4CAF50;
                border-radius: 10px;
                padding: 15px;
                margin: 10px 0;
            }
            .respuesta-title {
                color: #4CAF50;
                font-weight: bold;
                font-size: 18px;
                margin-bottom: 10px;
            }
            </style>
            """, 
            unsafe_allow_html=True
        )
# URL del logo
logo_url = "https://wompi.com/assets/downloadble/logos_wompi/Wompi_LogoPrincipal.png"

# Variables para la selecci√≥n de secciones
if 'selected_main' not in st.session_state:
    st.session_state.selected_main = "1"
    
# Barra lateral con el logo y men√∫
with st.sidebar:
    st.image(logo_url, use_column_width=True)  # Muestra el logo desde la URL
    st.title("Men√∫ Principal")

     # Botones principales para secciones en filas de 5 columnas
    cols = st.columns(5)
    buttons = ["1", "2", "3", "4", "5", "6", "7", "8", "9", "10", "11"]
    
    for i, button in enumerate(buttons):
        if cols[i % 5].button(button):
            st.session_state.selected_main = button

    
    # Bot√≥n para cambiar entre modo claro y oscuro con √≠conos de sol y luna
    theme_button = "üåô" if not st.session_state.dark_mode else "‚òÄÔ∏è"
    # st.button(theme_button, on_click=toggle_theme)

# Men√∫ horizontal a la derecha basado en la selecci√≥n
st.title("Prueba T√©cnica Proceso Cient√≠fico de Datos")
st.subheader("Presentado por: Daniel Grass")



if st.session_state.selected_main:
    # Mostrar un men√∫ horizontal seg√∫n la selecci√≥n del bot√≥n principal
    if st.session_state.selected_main == "1":
        
        # Generar datos aleatorios con ruido alrededor de una par√°bola
        np.random.seed(42)
        x = np.linspace(-10, 10, 100)
        y_real = 0.5 * x**2 - 3 * x + 2
        y_noise = y_real + np.random.normal(0, 5, x.shape[0])

        # Convertir a un DataFrame para facilitar el manejo
        data = pd.DataFrame({'x': x, 'y': y_noise})

        # T√≠tulo de la aplicaci√≥n
        st.title('1. Sesgo y Varianza')
        st.write("Describe en qu√© consiste el trade-off entre sesgo y varianza al entrenar un modelo. Y dibuja un ejemplo en un plano cartesiano en el que se ilustre un modelo con alto sesgo y otro con alta varianza.")
     
        

        # Contenido del cuadro de texto
        st.markdown(
             """
            <div class="respuesta-box">
                <div class="respuesta-title">Respuesta</div>
                En el entrenamiento de modelos de aprendizaje autom√°tico, el intercambio entre sesgo y varianza es un concepto clave. Se refiere al equilibrio entre dos fuentes de error que tienen un impacto en la capacidad del modelo para generalizar adecuadamente a datos nuevos:
                Cuando un modelo es demasiado simple para capturar las relaciones complejas en los datos, ocurre el <strong>sesgo</strong>. Un modelo con alto <strong>sesgo</strong> puede <strong>subajustar</strong>, lo que significa que hace predicciones inexactas y no aprende lo suficiente de los datos de entrenamiento. Por ejemplo, aplicar una regresi√≥n lineal a un conjunto de datos no lineales.
                La <strong>varianza</strong> es el error que ocurre cuando un modelo est√° demasiado ajustado a los datos de entrenamiento y es demasiado complejo. Un modelo que tiene una alta varianza puede <strong>sobreajustar</strong> (overfitting), lo que significa que se ajusta demasiado a las peculiaridades del conjunto de entrenamiento y falla al generalizar a nuevos datos.
                Encontrar un equilibrio adecuado entre el sesgo y la varianza es un desaf√≠o. El modelo ideal tiene un sesgo bajo y una varianza baja, lo que le permite un buen ajuste y generalizaci√≥n.
            </div>
            """,
            unsafe_allow_html=True
        )

        # Gr√°fica 1: Regresi√≥n Lineal (Alto Sesgo)
        st.subheader('Gr√°fica 1: Alto Sesgo')
        lr = LinearRegression()
        lr.fit(x.reshape(-1, 1), y_noise)
        y_pred_lineal = lr.predict(x.reshape(-1, 1))

        # Crear la figura con plotly
        fig1 = go.Figure()
        fig1.add_trace(go.Scatter(x=x, y=y_noise, mode='markers', name='Datos'))
        fig1.add_trace(go.Scatter(x=x, y=y_pred_lineal, mode='lines', name='Regresi√≥n Lineal', line=dict(color='red')))
        st.plotly_chart(fig1)

        # Gr√°fica 2: Alta Varianza (Rectas que pasan por los puntos)
        st.subheader('Gr√°fica 2: Alta Varianza')
        fig2 = go.Figure()
        fig2.add_trace(go.Scatter(x=x, y=y_noise, mode='markers', name='Datos'))
        fig2.add_trace(go.Scatter(x=x, y=y_noise, mode='lines', name='Alta Varianza', line=dict(color='purple')))
        st.plotly_chart(fig2)

        # Gr√°fica 3: Ajuste Cuadr√°tico (Bajo Sesgo y Baja Varianza)
        st.subheader('Gr√°fica 3: Bajo Sesgo y Baja Varianza')
        p = Polynomial.fit(x, y_noise, 2)
        y_pred_cuadratic = p(x)

        # Crear la figura con plotly
        fig3 = go.Figure()
        fig3.add_trace(go.Scatter(x=x, y=y_noise, mode='markers', name='Datos'))
        fig3.add_trace(go.Scatter(x=x, y=y_pred_cuadratic, mode='lines', name='Ajuste Cuadr√°tico', line=dict(color='green')))
        st.plotly_chart(fig3)
    elif st.session_state.selected_main == "2":
         # T√≠tulo de la aplicaci√≥n
        st.title('2. Modelo de clasificaci√≥n - F1 score')
        st.write("Est√°s entrenando un modelo de clasificaci√≥n y obtienes un F1 score de 0.91 en el conjunto de entrenamiento y un F1 score de 0.18 en validaci√≥n, ¬øcu√°les de las siguientes opciones utilizar√≠as para resolver este problema?")
        st.write("a. Buscar variables nuevas que representen mejor el objetivo.")
        st.write("b. Boosting.")
        st.write("c. Disminuir la regularizaci√≥n.")
        st.write("d. Simplificar el modelo.")
        st.write("e. Regularizar el modelo.")

        # Contenido del cuadro de texto
        st.markdown(
             """
            <div class="respuesta-box">
                <div class="respuesta-title">Respuesta</div>
                Una de las formas m√°s efectivas de combatir el sobreajuste es mediante la <strong>regularizaci√≥n del modelo (opci√≥n e)</strong>. La regularizaci√≥n (L1, L2 o una combinaci√≥n) penaliza los par√°metros del modelo para evitar que se ajusten demasiado a los datos de entrenamiento, lo que mejora su capacidad de generalizaci√≥n al reducir la varianza causada por la complejidad excesiva. Adem√°s, otra soluci√≥n viable es <strong>simplificar el modelo (opci√≥n d)</strong>. Al reducir el n√∫mero de par√°metros, ya sea usando menos capas en una red neuronal o eliminando caracter√≠sticas redundantes, se puede mejorar a√∫n m√°s la capacidad de generalizaci√≥n, especialmente cuando el modelo es demasiado complejo.
                Buscar nuevas variables (opci√≥n a), aunque √∫til para mejorar el modelo, no resuelve directamente el sobreajuste, que es el problema principal aqu√≠. El boosting (opci√≥n b), al agregar complejidad, podr√≠a empeorar el sobreajuste al hacer que el modelo se ajuste a√∫n m√°s a las particularidades del conjunto de entrenamiento. Por otro lado, disminuir la regularizaci√≥n (opci√≥n c)reducir√≠a el control sobre la complejidad del modelo, lo que aumentar√≠a a√∫n m√°s el ajuste a los datos de entrenamiento y empeorar√≠a la capacidad de generalizaci√≥n. En este caso, lo m√°s adecuado es simplificar y/o regularizar el modelo para reducir la varianza y mejorar la generalizaci√≥n.            </div>
            """,
            unsafe_allow_html=True
        )

    elif st.session_state.selected_main == "3":
        

        st.title("3. Modelo de Regresi√≥n - MSE")
        st.write("Te presentan los siguientes resultados de unos modelos usados para resolver el mismo problema de regresi√≥n:")

        # Crear los datos de la tabla en un DataFrame
        data = {
            'Algoritmo': ['Regresi√≥n Polin√≥mica', '√Årbol de decisi√≥n', 'M√°quinas de Soporte Vectorial', 'XGBoost'],
            'Error Cuadr√°tico Medio (MSE)': [0.59, 0.78, 0.93, 0.57]
        }

        df = pd.DataFrame(data)

        # Mostrar la tabla
        st.write(df)

        # Pregunta a.
        st.write("### a. Argumenta cu√°l modelo seleccionar√≠as para desplegar en producci√≥n")

        # Primer bloque de respuesta (equivalente a tcolorbox)
        st.markdown(
            """
            <div style="background-color: #e6f4e6; border-left: 5px solid #4CAF50; padding: 10px; border-radius: 5px;">
            <strong>Respuesta:</strong> El modelo XGBoost tiene el menor MSE (0.57), lo que indica que sus predicciones son m√°s cercanas a los valores reales en comparaci√≥n con otros modelos, reflejando un mejor rendimiento en precisi√≥n. Aunque la regresi√≥n polin√≥mica es m√°s f√°cil de interpretar y tiene un MSE bajo (0.59), es importante considerar la complejidad del modelo. Para garantizar la consistencia de los resultados, es recomendable realizar validaci√≥n cruzada o pruebas con datos independientes antes de tomar una decisi√≥n final. Para su implementaci√≥n en producci√≥n, tambi√©n se debe evaluar el impacto de la complejidad del modelo en los recursos computacionales.
            </div>
            """, 
            unsafe_allow_html=True
        )

        # Pregunta b.
        st.write("### b. ¬øTe parece indicada la m√©trica de desempe√±o seleccionada? ¬øPlantear√≠as otra m√©trica?")

        # Segundo bloque de respuesta (equivalente a tcolorbox)
        st.markdown(
            """
            <div style="background-color: #e6f4e6; border-left: 5px solid #4CAF50; padding: 10px; border-radius: 5px;">
            <strong>Respuesta:</strong> El Error Cuadr√°tico Medio (MSE), la m√©trica elegida, es adecuada porque penaliza m√°s severamente los errores grandes, lo que puede ser √∫til cuando esos errores son cr√≠ticos. Pero combinarla con otras m√©tricas puede dar una evaluaci√≥n m√°s completa. Por ejemplo, debido a que se encuentra en las mismas unidades que la variable objetivo, la Ra√≠z del Error Cuadr√°tico Medio (RMSE) es m√°s f√°cil de interpretar. El Error Medio (ME) podr√≠a ser √∫til para determinar si el modelo tiene subajuste o sobreajuste. El Error Medio Absoluto (MAD) ser√≠a m√°s robusto frente a valores at√≠picos. Finalmente, si queremos interpretar los errores en t√©rminos porcentuales, el Error Porcentual Absoluto Medio (MAPE) lo hace independiente de la escala de los datos y permite la comparaci√≥n entre diferentes conjuntos de datos o modelos.
            </div>
            """, 
            unsafe_allow_html=True
        )
    elif st.session_state.selected_main == "4":
        st.title("4. Problema de clasificaci√≥n binario")
        st.write("En un problema de clasificaci√≥n binario entrenas un modelo cuya curva ROC es la siguiente:")

        # Mostrar la imagen ROC
        st.image('images/g4.png', caption='Curva ROC con AUC = 0.31',  width=300)

        # Descripci√≥n del problema
        st.write("""
        Un colega te dice que tendr√≠as mejor resultado clasificando los datos lanzando una moneda, 
        (cara para positivo y sello para negativo). Argumenta si esto es cierto o no.
        """)

        # Cuadro con la justificaci√≥n (simulando tcolorbox)
        st.markdown(
            """
            <div style="background-color: #e6f4e6; border-left: 5px solid #4CAF50; padding: 10px; border-radius: 5px;">
            <strong>El colega tiene raz√≥n</strong> . La capacidad del modelo para distinguir entre clases se mide por el AUC (√Årea Bajo la Curva ROC), y un valor de 0.5 corresponde al rendimiento de un clasificador aleatorio, como lanzar una moneda (cara para positivo, sello para negativo). Esto se debe a que tienes una probabilidad del 50% de acertar cada predicci√≥n en un clasificador aleatorio.

            El desempe√±o del modelo es peor que el de un clasificador aleatorio, como se muestra en la gr√°fica, con una AUC de 0.31, un valor significativamente por debajo de 0.5. De hecho, un AUC tan bajo indica que el modelo est√° clasificando incorrectamente m√°s veces de lo que lo har√≠a al azar.
            </div>
            """, 
            unsafe_allow_html=True
        )
        st.image('images/g5.png', caption='Curva ROC con AUC = 0.5',  width=300)
    elif st.session_state.selected_main == "5":
        st.title("5. An√°lisis de redes - fraude")
        st.write("""
        Tienes los siguientes atributos de una transacci√≥n de pago que realiz√≥ un consumidor en una tienda de ecommerce:
        """)

        # Lista de atributos de la transacci√≥n
        st.markdown("""
        - Id de la transacci√≥n.
        - Fecha y hora de la transacci√≥n.
        - Monto de la transacci√≥n.
        - Correo electr√≥nico del pagador.
        - Tel√©fono del pagador.
        - C√©dula del pagador.
        - Id de la tienda en la que se realiz√≥ la compra.
        - Id de la tarjeta de cr√©dito con la que se realiz√≥ la compra.
        """)

        # Descripci√≥n del proyecto
        st.write("""
        Con esta informaci√≥n imagina que te asignan un proyecto en el que debes construir un grafo que te ayude a encontrar pagadores que puedan representar riesgo de fraude.
        """)

        # Subsecci√≥n a.
        st.write("### a. Dibuja el esquema del grafo que construir√≠as")

        # Cargar y mostrar im√°genes del grafo
        st.image('images/g6.jpg')
        st.image('images/g7.jpg')
        st.image('images/g8.jpg')  
        # Subsecci√≥n b.
        st.write("### b. ¬øC√≥mo usar√≠as este grafo para identificar usuarios con alto riesgo de fraude?")

        # Cuadro de texto con el an√°lisis (simulando tcolorbox)
        st.markdown(
            """
            <div style="background-color: #e6f4e6; border-left: 5px solid #4CAF50; padding: 10px; border-radius: 5px;">
            <strong>An√°lisis:</strong> El grafo puede detectar patrones de comportamiento inusuales. Podr√≠as buscar, por ejemplo:
            <ul>
                <li><strong>Los pagadores est√°n conectados a varias tarjetas:</strong> Si un pagador usa m√∫ltiples tarjetas en diferentes transacciones, esto puede indicar fraude.</li>
                <li><strong>Tarjetas de cr√©dito compartidas entre pagadores:</strong> Si dos o m√°s pagadores utilizan la misma tarjeta de cr√©dito en diferentes tiendas, esto puede indicar actividad fraudulenta.</li>
                <li><strong>Tendencias en el tiempo:</strong> Utilizando las fechas y horas de las transacciones, podr√≠as encontrar patrones como un n√∫mero excesivamente alto de transacciones en un per√≠odo de tiempo relativamente corto.</li>
            </ul>
            
            <p>Por ejemplo, para el usuario 1 y el usuario 2, podemos observar en el grafo que ambos est√°n conectados a la misma tarjeta de cr√©dito (CD 2) y participaron en las transacciones 3 y 4, respectivamente. Esta coincidencia en el uso de una tarjeta compartida puede ser un indicio de comportamiento sospechoso, ya que es inusual que diferentes usuarios leg√≠timos compartan una tarjeta de cr√©dito, a menos que sean parte del mismo n√∫cleo familiar o se conozcan personalmente.</p>

            <p>Los algoritmos de detecci√≥n de fraudes basados en grafos, como las redes neuronales en grafos (GNN) o el an√°lisis de similitud, pueden ayudar a identificar patrones ocultos en los datos de comportamiento de los usuarios.</p>
            </div>
            """, 
            unsafe_allow_html=True
        )
    elif st.session_state.selected_main == "6":
        st.title("6. SQL Transactions")
        st.write("""
        En una base de datos SQL tienes una tabla llamada `transactions`, la cual registra transacciones de pagos y cuenta con el siguiente esquema:
        """)

        # Crear una tabla en Streamlit usando markdown
        st.markdown("""
        <table border="1" cellspacing="0" cellpadding="5">
        <thead>
            <tr>
            <th>columna</th>
            <th>tipo</th>
            <th>descripci√≥n</th>
            </tr>
        </thead>
        <tbody>
            <tr>
            <td><code>id</code></td>
            <td><code>VARCHAR</code></td>
            <td>Identificador √∫nico de cada transacci√≥n</td>
            </tr>
            <tr>
            <td><code>created_at</code></td>
            <td><code>TIMESTAMP</code></td>
            <td>Momento de creaci√≥n de la transacci√≥n</td>
            </tr>
            <tr>
            <td><code>payment_method_type</code></td>
            <td><code>VARCHAR</code></td>
            <td>M√©todo de pago</td>
            </tr>
            <tr>
            <td><code>status_message</code></td>
            <td><code>VARCHAR</code></td>
            <td>Mensaje del estado de la transacci√≥n</td>
            </tr>
            <tr>
            <td><code>amount</code></td>
            <td><code>INT8</code></td>
            <td>Monto en pesos</td>
            </tr>
        </tbody>
        </table>
        """, unsafe_allow_html=True)

        # Explicaci√≥n del query
        st.write("""
        Escribe un query en SQL que retorne la cantidad de transacciones por mensaje (`status_message`) y la participaci√≥n porcentual de ese estado del total de transacciones, para el mes de agosto de 2024 y el medio de pago `'NEQUI'`.
        """)
        # Generar un DataFrame con al menos 500 registros
        np.random.seed(42)

        # Opciones para las columnas categ√≥ricas
        payment_method_type = ['NEQUI', 'Transferencia bancolombia', 'otra']
        status_message = ['invalida', 'confirmada', 'con_error', 'cancelada']

        # Generar 500 registros con datos aleatorios (timestamps para agosto de 2024)
        data = {
            'id': [f'TRX_{i+1}' for i in range(5000)],
            'created_at': np.random.randint(1707827200, 1730419200, 5000),  # Timestamps para agosto 2024
            'payment_method_type': np.random.choice(payment_method_type, size=5000),
            'status_message': np.random.choice(status_message, size=5000),
            'amount': np.random.randint(1000, 100000, size=5000)
        }
        st.markdown(
            """
            <div style="background-color: #e6f4e6; border-left: 5px solid #4CAF50; padding: 10px; border-radius: 5px;">
            <strong>Generaci√≥n de datos aleatorios:</strong>
            <p>En este ejemplo, se generar√°n <strong>5000 registros de transacciones</strong> de manera aleatoria utilizando la librer√≠a <code>numpy</code>. Para las transacciones, se generar√°n los siguientes campos:</p>
            <ul>
                <li><strong>ID de transacci√≥n</strong>: Identificador √∫nico para cada transacci√≥n, con el formato <code>TRX_1</code>, <code>TRX_2</code>, ..., <code>TRX_5000</code>.</li>
                <li><strong>Fecha y hora de la transacci√≥n (created_at)</strong>: Se generan timestamps en formato UNIX que corresponden a fechas del 2024.</li>
                <li><strong>M√©todo de pago (payment_method_type)</strong>: Se seleccionar√° de manera aleatoria entre tres opciones: <code>'NEQUI'</code>, <code>'Transferencia bancolombia'</code>, y <code>'otra'</code>.</li>
                <li><strong>Estado de la transacci√≥n (status_message)</strong>: Se generar√° aleatoriamente uno de los siguientes valores: <code>'invalida'</code>, <code>'confirmada'</code>, <code>'con_error'</code>, <code>'cancelada'</code>.</li>
                <li><strong>Monto (amount)</strong>: Se generar√° un valor aleatorio en pesos entre $1,000 y $100,000.</li>
            </ul>
            <p>Este conjunto de datos simula las transacciones de un sistema de pagos para un an√°lisis posterior.</p>
            </div>
            """,
            unsafe_allow_html=True
        )
        transactions = pd.DataFrame(data)
        st.write(transactions)
        st.markdown(
            """
            <div style="background-color: #e6f4e6; border-left: 5px solid #4CAF50; padding: 10px; border-radius: 5px;">
            <strong>Se utilizar√° una consulta en SQL</strong> para obtener la <strong>cantidad de transacciones por estado (<code>status_message</code>)</strong> y su <strong>participaci√≥n porcentual</strong> en relaci√≥n con el total de transacciones del mes de agosto de 2024 y el m√©todo de pago <code>'NEQUI'</code>. La estructura de la consulta es la siguiente:
            <ol>
                <li><strong>Filtrado de datos</strong>: Filtramos solo las transacciones realizadas con el m√©todo de pago <code>'NEQUI'</code> y que corresponden a agosto de 2024.</li>
                <li><strong>Agrupaci√≥n por estado de la transacci√≥n</strong>: Agrupamos las transacciones por el campo <code>status_message</code>, lo que nos permitir√° contar cu√°ntas transacciones se realizaron para cada estado.</li>
                <li><strong>C√°lculo de participaci√≥n porcentual</strong>: Calculamos el porcentaje que representa cada tipo de mensaje (<code>status_message</code>) en relaci√≥n con el total de transacciones con el m√©todo <code>'NEQUI'</code>.</li>
            </ol>
            </div>
            """, 
            unsafe_allow_html=True
        )
        # Query para la cantidad de transacciones por mensaje (status_message) y la participaci√≥n porcentual de ese estado del total de transacciones, para agosto de 2024 y el medio de pago 'NEQUI'
        query = """
            SELECT status_message, 
                COUNT(*) as cantidad_transacciones,
                (COUNT(*) * 100.0 / (SELECT COUNT(*) FROM transactions WHERE payment_method_type = 'NEQUI' AND strftime('%Y-%m', datetime(created_at, 'unixepoch')) = '2024-08')) as participacion_porcentual
            FROM transactions
            WHERE payment_method_type = 'NEQUI' 
                AND strftime('%Y-%m', datetime(created_at, 'unixepoch')) = '2024-08'
            GROUP BY status_message;
        """
        
        st.image('images/g9.png')  
        # Ejecutar la consulta con pandasql
        result = ps.sqldf(query, locals())

        st.write("Resultado consulta:")
        st.write(result)

    elif st.session_state.selected_main == "7":
        st.title("7. Spark")

        # Descripci√≥n inicial
        st.write("""
        Acabas de escribir un script en Spark para procesar un archivo de 8 millones de registros. Lo ejecutas en un laptop con 16GB de RAM y un procesador de √∫ltima generaci√≥n. Despu√©s lo ejecutas en un entorno distribuido de nodos de 3GB de RAM y procesadores sencillos (sumando los nodos tienen menos recursos de c√≥mputo que tu equipo). El mismo script tiene un tiempo de ejecuci√≥n menor en el entorno distribuido que en el entorno local, explica porque ocurre esto.
        """)

        # Cuadro de explicaci√≥n con color de fondo
        st.markdown(
            """
            <div style="background-color: #e6f4e6; border-left: 5px solid #4CAF50; padding: 10px; border-radius: 5px;">
            <strong>Spark divide los 8 millones de registros en m√∫ltiples particiones en un entorno distribuido y procesa cada partici√≥n en paralelo en varios nodos, lo que permite que el trabajo se realice m√°s r√°pido, incluso si cada nodo tiene menos capacidad.</strong> Spark en un solo equipo puede ralentizar la ejecuci√≥n debido a cuellos de botella de memoria y operaciones de I/O, a pesar de que su laptop tiene m√°s RAM y un procesador m√°s potente. Los nodos en un cl√∫ster distribuido gestionan mejor la memoria y el procesamiento paralelo mejora el rendimiento. Spark utiliza la distribuci√≥n de trabajo, lo que explica por qu√©, a pesar de los recursos limitados de cada nodo, el tiempo de ejecuci√≥n es menor en el entorno distribuido. 
            <a href='https://medium.com/@sephinreji98/understanding-spark-cluster-modes-client-vs-cluster-vs-local-d3c41ea96073' target='_blank'>M√°s informaci√≥n</a>
            </div>
            """,
            unsafe_allow_html=True
        )
    elif st.session_state.selected_main == "8":
        st.title("8. Datalake en S3")

        # Descripci√≥n inicial
        st.write("""
        La nueva aplicaci√≥n m√≥vil genera registros de todas las interacciones de los usuarios. Vas a construir un modelo de segmentaci√≥n de usuarios y el primer paso es consolidar estos registros en un data lake en S3. Puedes almacenar la informaci√≥n en formato CSV o Parquet y las estimaciones del tama√±o en disco de cada formato para los registros de 1 mes son las siguientes:
        """)

        # Crear el DataFrame para la tabla de Formatos
        data_format = pd.DataFrame({
            "Formato": ["CSV", "Parquet"],
            "Tama√±o en disco": ["1TB", "130GB"]
        })

        # Mostrar la tabla de Formatos
        st.write("### Formatos de almacenamiento")
        st.write(data_format)

        # Pregunta a.
        st.subheader("a. ¬øCu√°l formato eliges? Argumenta tu respuesta.")

        # Cuadro de respuesta
        st.markdown(
            """
            <div style="background-color: #e6f4e6; border-left: 5px solid #4CAF50; padding: 10px; border-radius: 5px;">
            <strong>Elegir√≠a el formato Parquet</strong> porque, al ser columnar, permite una mayor compresi√≥n y eficiencia de lectura para grandes vol√∫menes de datos, lo que reduce significativamente el espacio en disco (130GB frente a 1TB) y mejora el rendimiento en an√°lisis.
            </div>
            """, 
            unsafe_allow_html=True
        )

        # Pregunta b.
        st.subheader("b. ¬øQu√© ventajas y desventajas encuentras en cada formato? Argumenta tu respuesta.")

        # Tabla de ventajas y desventajas
        st.markdown("""
        | **Formato** | **Ventajas**                                               | **Desventajas**                                                      |
        |-------------|-------------------------------------------------------------|----------------------------------------------------------------------|
        | CSV         | - F√°cil de leer en cualquier editor de texto.               | - Tama√±o de archivo grande.                                           |
        |             | - No requiere software especializado.                      | - Procesamiento lento en grandes vol√∫menes de datos.                  |
        | Parquet     | - Alta compresi√≥n y menor uso de disco.                    | - Requiere herramientas compatibles para lectura.                     |
        |             | - Eficiente para consultas anal√≠ticas.                      | - M√°s complejo para manipulaci√≥n manual.                              |
        """)
    elif st.session_state.selected_main == "9":
        st.title("9. Anomal√≠as Transacciones")

        # Descripci√≥n inicial
        st.write("""
        El pasado martes 17 de septiembre cursaron 188,756 transacciones por el sistema. La media de los 10 martes anteriores es de 191,050 transacciones. La mediana de los 10 martes anteriores es de 90,968 transacciones. Si comparo el 17 de septiembre contra la media el d√≠a parece normal, pero si lo comparo contra la mediana el tr√°fico es significativamente mayor. ¬øDeber√≠amos preocuparnos por algun compartamiento extra√±o el 17 de septiembre? ¬øqu√© recomendaciones me dar√≠as sobre esta medici√≥n?
        """)

        # Cuadro de explicaci√≥n con color de fondo
        st.markdown(
            """
            <div style="background-color: #e6f4e6; border-left: 5px solid #4CAF50; padding: 10px; border-radius: 5px;">
            <strong>A pesar de que el n√∫mero de transacciones del 17 de septiembre parece ser similar al promedio de los 10 martes anteriores, la discrepancia con la mediana indica una distribuci√≥n asim√©trica de los datos.</strong> La media puede ser sesgada debido a valores √∫nicos (posibles at√≠picos) o d√≠as de gran tr√°fico, lo que la hace menos representativa de un martes normal. En presencia de estos valores extremos, la mediana muestra mejor el comportamiento central. El hecho de que las transacciones del 17 de septiembre est√©n mucho por encima de la mediana podr√≠a ser una se√±al de un comportamiento inusual. Es crucial investigar si el aumento de tr√°fico se debi√≥ a eventos extraordinarios, promociones o problemas t√©cnicos.

            Para monitorear el tr√°fico y detectar comportamientos an√≥malos, recomiendo utilizar modelos de pron√≥stico en series de tiempo univariadas como ARIMA, Prophet, modelos de suavizamiento exponencial o LSTM. Estos modelos permiten estimar un valor pronosticado y compararlo con el valor real. 

            Se define un intervalo de confianza con un l√≠mite superior e inferior, utilizando el error cuadr√°tico medio (MSE) como base. Un factor de seguridad ajusta el ancho del intervalo. Si el valor real cae fuera del rango esperado, se considera una anomal√≠a. Este enfoque proporciona una metodolog√≠a robusta para detectar variaciones inusuales en el tr√°fico y prevenir comportamientos an√≥malos.
            </div>
            """, 
            unsafe_allow_html=True
        )

        # Mostrar las im√°genes (aseg√∫rate de tener las im√°genes guardadas localmente)
        st.image("images/g12.png")
        st.image("images/g13.png")
        dates = pd.date_range(start='2020-04-01', end='2020-07-31', freq='D')
        y_hat = np.linspace(800, 1000, len(dates))  # Valores estimados
        mse = 10000
        s = 1.96  # Factor de seguridad para 95% de confianza
        ul = y_hat + s * np.sqrt(mse)  # Upper limit
        ll = y_hat - s * np.sqrt(mse)  # Lower limit
        y_real = y_hat + np.random.normal(0, 50, len(dates))  # Valores reales
        anomalies = [50, 60, 110, 120]  # Puntos de anomal√≠as

        # Introducir anomal√≠as en ciertos puntos
        y_real[anomalies] += np.random.normal(300, 20, len(anomalies))

        # Crear la figura
        fig = go.Figure()

        # Agregar l√≠nea de valor estimado (y_hat)
        fig.add_trace(go.Scatter(x=dates, y=y_hat, mode='lines', name='y_hat (estimated value)', line=dict(color='orange')))

        # Agregar l√≠mites superior (UL) e inferior (LL)
        fig.add_trace(go.Scatter(x=dates, y=ul, mode='lines', name='UL (Upper limit)', line=dict(color='purple')))
        fig.add_trace(go.Scatter(x=dates, y=ll, mode='lines', name='LL (Lower limit)', line=dict(color='purple')))

        # Agregar valores reales (y) sin anomal√≠as
        fig.add_trace(go.Scatter(x=dates, y=y_real, mode='markers', name='y (real value)', marker=dict(color='blue')))

        # Agregar anomal√≠as
        fig.add_trace(go.Scatter(x=dates[anomalies], y=y_real[anomalies], mode='markers', name='Anomalies', marker=dict(color='red', size=10)))

        # Etiquetas y dise√±o
        fig.update_layout(
            title="Detecci√≥n de Anomal√≠as",
            xaxis_title="Date [2020]",
            yaxis_title="Valor",
            legend_title="Leyenda",
            showlegend=True
        )

        # Mostrar gr√°fico en Streamlit
        st.plotly_chart(fig)
    elif st.session_state.selected_main == "10":
        st.title("10. Ruleta de casino")

        st.write("""
        Imagina que est√°s jugando a la ruleta en un casino. La ruleta tiene 18 espacios rojos, 18 espacios negros, y 2 verdes (cero y doble cero). En las √∫ltimas 8 tiradas ha salido rojo cada vez. Tu vecino en la mesa piensa que ahora es m√°s probable que salga negro en la siguiente tirada, dado que ha salido rojo tantas veces seguidas. ¬øQu√© opinas sobre las expectativas de tu vecino sobre de la pr√≥xima tirada?
        """)

        # Cuadro explicativo con color de fondo
        st.markdown(
            """
            <div style="background-color: #e6f4e6; border-left: 5px solid #4CAF50; padding: 10px; border-radius: 5px;">
            <strong>Las expectativas de tu vecino se basan en la falacia del jugador</strong>, que es la creencia err√≥nea de que procesos independientes influyen en las probabilidades de eventos pasados. Cada tirada de una ruleta es un evento independiente, lo que significa que la probabilidad de que salga rojo, negro o verde no cambia, sin importar lo que haya ocurrido antes.

            Las probabilidades de que salga un color en la siguiente tirada son las siguientes:
            <ul>
                <li><strong>Rojo:</strong> 18/38 </li>
                <li><strong>Negro:</strong> 18/38 </li>
                <li><strong>Verde (cero o doble cero): 2/38</li>
            </ul>
            La probabilidad de la pr√≥xima tirada no est√° influenciada por la secuencia de resultados anteriores (rojo en las √∫ltimas 8 tiradas), que sigue siendo la misma en cada tirada. Como cada tirada es independiente y no est√° influenciada por las tiradas anteriores, las <strong>expectativas de tu vecino son incorrectas</strong>.
            </div>
            """, 
            unsafe_allow_html=True
        )
    elif st.session_state.selected_main == "11":
        st.title("11. An√°lisis de Satisfacci√≥n")

        # Descripci√≥n inicial
        st.write("""
        Se presentan el histograma y el boxplot de las valoraciones de 1 a 10 proporcionadas por 1000 clientes sobre 3 servicios que ofrecemos (A, B y C). Una valoraci√≥n alta quiere decir que el cliente tiene una satisfacci√≥n alta.
        """)

        # Mostrar imagen
        st.image("images/g14.png")
        # Pregunta a. Asocia e indica cu√°l es el boxplot de cada histograma.
        st.subheader("a. Asocia e indica cu√°l es el boxplot de cada histograma.")

        st.markdown(
            """
            <div style="background-color: #e6f4e6; border-left: 5px solid #4CAF50; padding: 10px; border-radius: 5px;">
            <ul>
                <li><strong>A - 3:</strong> El histograma A muestra una distribuci√≥n casi uniforme de las valoraciones de satisfacci√≥n, lo que coincide con el boxplot 3, que presenta un rango amplio y dispersi√≥n equitativa.</li>
                <li><strong>B - 1:</strong> El histograma B tiene una distribuci√≥n sim√©trica con un pico en valores intermedios, lo cual coincide con el boxplot 1, que tiene una mediana central y presenta m√°s dispersi√≥n en los extremos (outliers).</li>
                <li><strong>C - 2:</strong> El histograma C tiene una distribuci√≥n sesgada hacia la izquierda con predominancia de valores bajos, lo cual coincide con el boxplot 2, que refleja esta misma tendencia con una mediana baja.</li>
            </ul>
            </div>
            """,
            unsafe_allow_html=True
        )       


        # Funci√≥n para visualizar las distribuciones sin remover outliers
        def plot_distribution(column, df):
            # Visualizaci√≥n inicial de la distribuci√≥n sin eliminar outliers
            fig_hist = px.histogram(df, x=column, nbins=50, title=f"Histograma de {column}", marginal="box")
            st.plotly_chart(fig_hist)

        # Generar datos de ejemplo
        np.random.seed(42)
        df = pd.DataFrame({
            'Servicio A': np.random.uniform(1, 10, 1000),
            'Servicio B': np.clip(np.random.normal(5, 1.5, 1000), 1, 10),
            'Servicio C': np.clip(np.random.exponential(1, 1000) * 3 + 1, 1, 10)
        })

        # Mostrar histogramas y boxplots para cada servicio sin eliminar outliers
        for column in df.columns:
            st.subheader(f"Distribuci√≥n para {column}")
            plot_distribution(column, df)

        
        # Pregunta b. ¬øEn cu√°l servicio no hay una percepci√≥n clara de la satisfacci√≥n?
        st.subheader("b. ¬øEn cu√°l servicio no hay una percepci√≥n clara de la satisfacci√≥n?")

        st.markdown(
            """
            <div style="background-color: #e6f4e6; border-left: 5px solid #4CAF50; padding: 10px; border-radius: 5px;">
            En el <strong>servicio A</strong>, la satisfacci√≥n no es clara. El histograma muestra una distribuci√≥n m√°s uniforme de las valoraciones, lo que indica que las opiniones est√°n dispersas en casi todos los niveles, sin una tendencia clara hacia la satisfacci√≥n alta o baja.
            </div>
            """,
            unsafe_allow_html=True
        )

        # Pregunta c. ¬øEn cu√°l servicio la satisfacci√≥n es muy baja?
        st.subheader("c. ¬øEn cu√°l servicio la satisfacci√≥n es muy baja?")

        st.markdown(
            """
            <div style="background-color: #e6f4e6; border-left: 5px solid #4CAF50; padding: 10px; border-radius: 5px;">
            En el <strong>servicio C</strong>, la satisfacci√≥n es baja. Tanto el histograma como el boxplot muestran que la mayor√≠a de los clientes otorgan valoraciones bajas, ya que hay una clara acumulaci√≥n de puntuaciones hacia el extremo inferior de la escala de satisfacci√≥n.
            </div>
            """,
            unsafe_allow_html=True
        )       
